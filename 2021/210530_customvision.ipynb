{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://docs.microsoft.com/ko-kr/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?tabs=visual-studio&pivots=programming-language-python#upload-and-tag-images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "pip install azure-cognitiveservices-vision-customvision"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-vision-customvision in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (1.1.27)\n",
      "Requirement already satisfied: msrest>=0.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (0.6.21)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (0.6.0)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (2020.6.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (1.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (1.25.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\r\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\r\n",
    "from msrest.authentication import ApiKeyCredentials\r\n",
    "import os, time, uuid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래 내용들 찾는법\n",
    " \n",
    "ENDPOINT : 포탈의 키 및 엔드포인트\n",
    "training_key : 포탈의 키 및 엔드포인트\n",
    "prediction_resource_id : 포털에서 커스텀비전 들어가서 속성"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "ENDPOINT = \"https://mledu-cuv21.cognitiveservices.azure.com/\"\r\n",
    "PRE_ENDPOINT = \"https://mleducuv21-prediction.cognitiveservices.azure.com/\"\r\n",
    "training_key = \"be34b8372fea4de48f4d1bea2f3e8f03\"\r\n",
    "prediction_key = \"f27f751a52c14cad9fa98021d0b7aa32\"\r\n",
    "prediction_resource_id = \"/subscriptions/fe07f267-115d-404d-8c01-dc1d36f23a4c/resourceGroups/MLEDU21/providers/Microsoft.CognitiveServices/accounts/MLEDUCuV21-Prediction\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\r\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\r\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\r\n",
    "predictor = CustomVisionPredictionClient(PRE_ENDPOINT, prediction_credentials)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "publish_iteration_name = \"classifyModel\"\r\n",
    "\r\n",
    "# Create a new project\r\n",
    "print (\"Creating project...\")\r\n",
    "project_name = uuid.uuid4()\r\n",
    "project = trainer.create_project(\"minipjt_test\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating project...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Make two tags in the new project\n",
    "neoguri_tag = trainer.create_tag(project.id, \"너구리\")\n",
    "charmcracker_tag = trainer.create_tag(project.id, \"참크래커\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "base_image_location = os.path.join (os.path.dirname(\"./\"), \"Images\")\n",
    "\n",
    "print(\"Adding images...\")\n",
    "\n",
    "image_list = []\n",
    "\n",
    "for image_num in range(1, 11):\n",
    "    file_name = \"neoguri_{}.jpg\".format(image_num)\n",
    "    with open(os.path.join (base_image_location, \"neoguri\", \"neoguri\"+str(image_num)+\".jpg\"), \"rb\") as image_contents:\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[neoguri_tag.id]))\n",
    "\n",
    "for image_num in range(1, 11):\n",
    "    file_name = \"charmcracker_{}.jpg\".format(image_num)\n",
    "    with open(os.path.join (base_image_location, \"charmcracker\", \"charmcracker\"+str(image_num)+\".jpg\"), \"rb\") as image_contents:\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[charmcracker_tag.id]))\n",
    "\n",
    "upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=image_list))\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    exit(-1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adding images...\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    print (\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Completed\n",
      "Waiting 10 seconds...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "\n",
    "headers = {\n",
    "    # Request headers\n",
    "    'Training-key': prediction_key,\n",
    "}\n",
    "\n",
    "params = urllib.parse.urlencode({\n",
    "})\n",
    "\n",
    "try:\n",
    "    conn = http.client.HTTPSConnection('japaneast.api.cognitive.microsoft.com')\n",
    "    conn.request(\"GET\", \"/customvision/v3.3/Training/projects/5ebe1537-dad2-4ef4-b2a2-73fc3cf1af0c/iterations?%s\" % params, \"{body}\", headers)\n",
    "    response = conn.getresponse()\n",
    "    data = response.read()\n",
    "    print(data)\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'{\"error\":{\"code\":\"401\",\"message\": \"The GetIterations Operation under Custom_Vision_Training_3.3 is not supported with the current subscription key and pricing tier Custom_Vision.Prediction.S0.\"}}'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PRE_ENDPOINT, prediction_credentials)\n",
    "\n",
    "with open(os.path.join (base_image_location, \"Test/test_image.jpg\"), \"rb\") as image_contents:\n",
    "    results = predictor.classify_image(project.id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "    # Display the results.\n",
    "    for prediction in results.predictions:\n",
    "        print(\"\\t\" + prediction.tag_name +\n",
    "              \": {0:.2f}%\".format(prediction.probability * 100))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "CustomVisionErrorException",
     "evalue": "Invalid iteration",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCustomVisionErrorException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-90b7a16968b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbase_image_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Test/test_image.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage_contents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpublish_iteration_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_contents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Display the results.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\azure\\cognitiveservices\\vision\\customvision\\prediction\\operations\\_custom_vision_prediction_client_operations.py\u001b[0m in \u001b[0;36mclassify_image\u001b[1;34m(self, project_id, published_name, image_data, application, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCustomVisionErrorException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCustomVisionErrorException\u001b[0m: Invalid iteration"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import requests\n",
    "import json\n",
    "import html\n",
    "url=\"https://mledu-cuv21.cognitiveservices.azure.com/customvision/v3.0/Prediction/77d3d89e-3bf9-4367-a0ae-e6b2db459289/classify/iterations/Iteration1/image\"\n",
    "headers={'content-type':'application/octet-stream','Prediction-Key':'f27f751a52c14cad9fa98021d0b7aa32'}\n",
    "response =requests.post(url,data=open(\"./Images/Test/test_image.jpg\",\"rb\"),headers=headers)\n",
    "analysis = response.json()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "print(analysis)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id': '5bd0c8e4-6f3b-4501-be66-683a53330f04', 'project': '77d3d89e-3bf9-4367-a0ae-e6b2db459289', 'iteration': '8e8d79ff-3789-4bb8-87e8-226ec4dfb07f', 'created': '2021-05-30T15:11:10.793Z', 'predictions': [{'probability': 0.99999905, 'tagId': '8669d6e7-e558-4d30-a266-bc02465baed6', 'tagName': '너구리'}, {'probability': 8.6426735e-07, 'tagId': 'cc4143d1-2aed-4e57-8f9b-83a5c06ce47a', 'tagName': '참크래커'}]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print(analysis['predictions'][0]['tagName'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "너구리\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}